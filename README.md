# ğŸŒŒ MetaGNN-MAML-Replication â€” Graph-Based Molecular Property Prediction

This repository provides a **forward-only PyTorch replication** of the  
**MetaGNN architecture with MAML** for molecular property prediction.

The focus is on **faithful replication of the paperâ€™s math and structure**, not benchmark optimization.  
It reproduces the core MetaGNN formulation â€” **GGNN-based message passing, edge-specific transformations, and meta-learning adaptation** â€” in concise, readable code.

Highlights include:

- Atom and bond embeddings propagation through GGNN blocks ğŸ”„  
- Edge-specific weight matrices for bond-aware message passing âœ¨  
- Meta-learning inner/outer loops for task adaptation ğŸ§©  

Paper reference: [MetaGNN-MAML: Graph Neural Networks with Meta-Learning for Molecular Property Prediction](https://arxiv.org/abs/2003.05996)

---

## Overview â€” Molecular Graph Modeling ğŸœ‚

![MetaGNN Overview](images/figmix.jpg)

> Molecular properties emerge from atom types, bonds, and their relational structure.

MetaGNN integrates:

- **GGNN encoder** for message passing over molecular graphs  
- **Edge networks** generating bond-specific transformations  
- **Residual updates** and readout for molecule-level prediction  
- **MAML / ANIL meta-learning** for fast adaptation to new molecular tasks  

This produces **graph-aware, task-adaptive molecular property predictions**.

---

## Molecular Graph Representation âš—ï¸

A molecule is represented by a graph:

$$
G = (V, E), \quad V = \{v_1, v_2, ..., v_n\}, \quad E = \{(v_i, v_j, e_{ij})\}
$$

with node features:

$$
h_i^0 = \text{AtomEmbed}(Z_i) \in \mathbb{R}^{F}
$$

and bond features $e_{ij}$ processed by an **edge network**:

$$
A_{ij} = \text{EdgeNetwork}(e_{ij}) \in \mathbb{R}^{F \times F}
$$

---

## GGNN Message Passing ğŸ”„

Each nodeâ€™s hidden state is updated via:

$$
m_v = \sum_{w \in \mathcal{N}(v)} A_{vw} h_w
$$

$$
h_v^{t+1} = \text{GRU}(m_v, h_v^t)
$$

Repeated for $T$ steps, this captures **neighbor and higher-order interactions** while maintaining **bond-awareness**.

---

## Readout Phase ğŸœ

After message passing, atom features are aggregated:

$$
\hat{y} = \text{Readout}\Big(h_1^T, h_2^T, ..., h_n^T\Big)
$$

This yields **molecular property predictions** (scalar or vector) per molecule.

---

## Meta-Learning Adaptation ğŸ§©

Meta-learning adapts the model to new tasks:

- **MAML:** Inner loop adapts **all model parameters** to a task:

$$
\theta' = \theta - \alpha \nabla_\theta \mathcal{L}_\text{support}(\theta)
$$

Outer loop updates the **meta-parameters** $\theta$ using the adapted parameters $\theta'$:

$$
\theta \gets \theta - \beta \nabla_\theta \sum_\text{tasks} \mathcal{L}_\text{query}(\theta')
$$

- **ANIL:** Inner loop updates **only the prediction head**, keeping the encoder fixed.

- **FOMAML (First-Order MAML):** Approximates MAML by **ignoring second-order gradients**, i.e., it does not compute gradients through the inner-loop updates. This makes training faster with slightly less precise meta-updates.

- **TaskSampler:** Generates random support/query splits per task for meta-learning.


---

## Why MetaGNN-MAML Matters ğŸ§ª

- Captures **graph-level relational structure** of molecules  
- Enables **fast adaptation** to new molecular prediction tasks  
- Maintains **readable, faithful replication** of the paperâ€™s math and blocks  
- Minimal implementation for education, research, and replication

---

## Repository Structure ğŸ—‚

```bash
MetaGNN-MAML-Replication/
â”œâ”€â”€ src/
â”‚
â”‚   â”œâ”€â”€ encoder/
â”‚   â”‚   â”œâ”€â”€ ggnn_encoder.py        # Message passing (m_v, h_v updates)
â”‚   â”‚   â”œâ”€â”€ edge_network.py        # Bond-specific weight matrices A_evw
â”‚   â”‚   â””â”€â”€ readout.py             # Sum aggregation + MLP output (Å·)
â”‚
â”‚   â”œâ”€â”€ meta_learning/
â”‚   â”‚   â”œâ”€â”€ maml.py                # MAML inner/outer loop equations
â”‚   â”‚   â”œâ”€â”€ fo_maml.py             # First-order MAML (no second-order grads)
â”‚   â”‚   â”œâ”€â”€ anil.py                # Head-only adaptation (ANIL variant)
â”‚   â”‚   â””â”€â”€ task_sampler.py        # Task creation for meta-learning
â”‚
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â””â”€â”€ meta_gnn_model.py      # Encoder + prediction head
â”‚
â”‚   â””â”€â”€ config.py                  # Paper hyperparameters
â”‚
â”œâ”€â”€ images/
â”‚   â””â”€â”€ figmix.jpg                  # Model overview figure
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
---


## ğŸ”— Feedback

For questions or feedback, contact: [barkin.adiguzel@gmail.com](mailto:barkin.adiguzel@gmail.com)
